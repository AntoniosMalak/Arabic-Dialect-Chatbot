{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import utlis\n",
        "\n",
        "def train(data, words, classes, models):\n",
        "    data_path = 'data/' + data\n",
        "    words_path = 'words/' + words\n",
        "    classes_path = 'classes/' + classes\n",
        "    models_path = 'models/' + models\n",
        "\n",
        "    words, classes, documents = utlis.get_weight(data_path, words_path, classes_path)\n",
        "    X_train, y_train = utlis.get_train_data(words, classes, documents)\n",
        "    model = utlis.train_model(X_train, y_train, models_path)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wapg1SS0gccW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38 documents\n",
            "8 classes\n",
            "82 unique lemmatized words\n",
            "words and classes are saved\n",
            "Model is saved\n",
            " evaluate model\n",
            "2/2 [==============================] - 1s 6ms/step - loss: 4.9494e-05 - accuracy: 1.0000\n",
            "Test set\n",
            "  Loss: 0.000\n",
            "  Accuracy: 1.000\n"
          ]
        }
      ],
      "source": [
        "eg_model = train('EG_data.json', 'eg_words.pkl', 'eg_classes.pkl', 'eg_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29 documents\n",
            "8 classes\n",
            "73 unique lemmatized words\n",
            "words and classes are saved\n",
            "Model is saved\n",
            " evaluate model\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 7.5356e-05 - accuracy: 1.0000\n",
            "Test set\n",
            "  Loss: 0.000\n",
            "  Accuracy: 1.000\n"
          ]
        }
      ],
      "source": [
        "gu_model = train('GU_data.json', 'gu_words.pkl', 'gu_classes.pkl', 'gu_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38 documents\n",
            "8 classes\n",
            "85 unique lemmatized words\n",
            "words and classes are saved\n",
            "Model is saved\n",
            " evaluate model\n",
            "2/2 [==============================] - 1s 9ms/step - loss: 3.0901e-05 - accuracy: 1.0000\n",
            "Test set\n",
            "  Loss: 0.000\n",
            "  Accuracy: 1.000\n"
          ]
        }
      ],
      "source": [
        "le_model = train('LE_data.json', 'le_words.pkl', 'le_classes.pkl', 'le_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38 documents\n",
            "8 classes\n",
            "91 unique lemmatized words\n",
            "words and classes are saved\n",
            "Model is saved\n",
            " evaluate model\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1067e-05 - accuracy: 1.0000\n",
            "Test set\n",
            "  Loss: 0.000\n",
            "  Accuracy: 1.000\n"
          ]
        }
      ],
      "source": [
        "mg_model = train('MG_data.json', 'mg_words.pkl', 'mg_classes.pkl', 'mg_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38 documents\n",
            "8 classes\n",
            "63 unique lemmatized words\n",
            "words and classes are saved\n",
            "Model is saved\n",
            " evaluate model\n",
            "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function at 0x00000200A49CD7B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.8209e-05 - accuracy: 1.0000\n",
            "Test set\n",
            "  Loss: 0.000\n",
            "  Accuracy: 1.000\n"
          ]
        }
      ],
      "source": [
        "th_model = train('Arabic_data.json', 'th_words.pkl', 'th_classes.pkl', 'th_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "train_chatbot.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "06d551a9c38e3c9226fb791b081d443165cdefd6b8907d1070492d8de0992181"
    },
    "kernelspec": {
      "display_name": "Python 3.6.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
